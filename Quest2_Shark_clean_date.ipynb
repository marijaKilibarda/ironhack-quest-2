{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Date</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2024-09-16 00:00:00</td>\n",
       "      <td>2024.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-08-26 00:00:00</td>\n",
       "      <td>2024.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2024-08-06 00:00:00</td>\n",
       "      <td>2024.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2024-07-23 00:00:00</td>\n",
       "      <td>2024.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2024-07-18 00:00:00</td>\n",
       "      <td>2024.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                 Date    Year\n",
       "0   0  2024-09-16 00:00:00  2024.0\n",
       "1   1  2024-08-26 00:00:00  2024.0\n",
       "2   2  2024-08-06 00:00:00  2024.0\n",
       "3   3  2024-07-23 00:00:00  2024.0\n",
       "4   4  2024-07-18 00:00:00  2024.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel(\"GSAF5.xls\")\n",
    "\n",
    "df[\"id\"] = range(0, len(df))\n",
    "\n",
    "df_sharks = df[[\"id\", \"Date\", \"Year\"]]\n",
    "df_sharks.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_sharks.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATE CLEAN UP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Creo una nueva columna con Date_Comment para poder filtrar cada fila de Date en función del regex que le pase.\n",
    "2. Antes de aplicar Regex, elimino todas las celdas que contengan espacios, puntos, u otros valores raros al principio.\n",
    "3. Una vez hecho, aplico la regex y empiezo a calsifcar las celdas filtradas según su cmentairo en la columna Date_Comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xavie\\AppData\\Local\\Temp\\ipykernel_18344\\1468954483.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_sharks['Date_Comment']= 'Check'\n"
     ]
    }
   ],
   "source": [
    "df_sharks['Date_Comment']= 'Check'\n",
    "\n",
    "dateregex1 = r'\\d{2}-[A-Za-z]{3}-\\d{4}'\n",
    "dateregex2 = r'^\\d{4}$'\n",
    "dateregex3 = r'^\\d{4}-\\d{4}$'\n",
    "dateregex4 = r'^Before \\d{4}$'\n",
    "dateregex5 = r'^Reported \\d{2}-[A-Za-z]{3}-\\d{4}$'\n",
    "dateregex6 = r'^[A-Za-z]{3}-\\d{4}$'\n",
    "\n",
    "\n",
    "df_sharks.loc[\n",
    "    df_sharks['Date'].str.match(dateregex1)==True,\n",
    "    'Date_Comment'\n",
    "    ]= \"Date, replace MMM, mm\"\n",
    "\n",
    "df_sharks.loc[\n",
    "    ((df_sharks[\"Date_Comment\"] == \"Check\")&\n",
    "    (df_sharks['Date'].str.match(dateregex2)==True)),\n",
    "    'Date_Comment'\n",
    "] = \"Only year, missing day and month\"\n",
    "\n",
    "df_sharks.loc[\n",
    "    ((df_sharks[\"Date_Comment\"] == \"Check\")&\n",
    "    (df_sharks['Date'].str.match(dateregex3)==True)),\n",
    "    'Date_Comment'\n",
    "] = \"YYYY-YYYY format-->Range of years\"\n",
    "\n",
    "df_sharks.loc[\n",
    "    ((df_sharks[\"Date_Comment\"] == \"Check\")&\n",
    "    (df_sharks['Date'].str.match(dateregex4)==True)),\n",
    "    'Date_Comment'\n",
    "] = \"Before YYYY format\"\n",
    "\n",
    "df_sharks.loc[\n",
    "    ((df_sharks[\"Date_Comment\"] == \"Check\")&\n",
    "    (df_sharks['Date'].str.match(dateregex5)==True)),\n",
    "    'Date_Comment'\n",
    "] = \"Reported dd-MMM-yyyy\"\n",
    "\n",
    "df_sharks.loc[\n",
    "    ((df_sharks[\"Date_Comment\"] == \"Check\")&\n",
    "    (df_sharks['Date'].str.match(dateregex6)==True)),\n",
    "    'Date_Comment'\n",
    "] = \"MMM-yyyy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date_Comment</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before YYYY format</th>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Check</th>\n",
       "      <td>671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date, replace MMM, mm</th>\n",
       "      <td>5278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MMM-yyyy</th>\n",
       "      <td>295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Only year, missing day and month</th>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Reported dd-MMM-yyyy</th>\n",
       "      <td>515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YYYY-YYYY format--&gt;Range of years</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Date\n",
       "Date_Comment                           \n",
       "Before YYYY format                   57\n",
       "Check                               671\n",
       "Date, replace MMM, mm              5278\n",
       "MMM-yyyy                            295\n",
       "Only year, missing day and month    138\n",
       "Reported dd-MMM-yyyy                515\n",
       "YYYY-YYYY format-->Range of years    16"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.pivot_table(df_sharks, index = \"Date_Comment\", values = \"Date\", aggfunc= \"count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xavie\\AppData\\Local\\Temp\\ipykernel_18344\\3724745412.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_sharks['Date_Comment']= 'Check'\n"
     ]
    }
   ],
   "source": [
    "df_sharks.loc[\n",
    "    df_sharks['Date_Comment'] ==\"Date, replace MMM, mm\",\n",
    "    \"Date\"\n",
    "]=df_sharks.loc[\n",
    "    df_sharks['Date_Comment'] ==\"Date, replace MMM, mm\",\n",
    "    \"Date\"].str.replace(\"Jan\",\"01\").str.replace(\"Feb\",\"02\").str.replace(\"Mar\",\"03\").str.replace(\"Apr\",\"04\").str.replace(\"May\",\"05\").str.replace(\"Jun\",\"06\").str.replace(\"Jul\",\"07\").str.replace(\"Aug\",\"08\").str.replace(\"Sep\",\"09\").str.replace(\"Oct\",\"10\").str.replace(\"Nov\",\"11\").str.replace(\"Dec\",\"12\")\n",
    "\n",
    "\n",
    "df_sharks.loc[\n",
    "    df_sharks['Date_Comment'] ==\"MMM-yyyy\",\n",
    "    \"Date\"\n",
    "]=df_sharks.loc[\n",
    "    df_sharks['Date_Comment'] ==\"MMM-yyyy\",\n",
    "    \"Date\"].str.replace(\"Jan\",\"01\").str.replace(\"Feb\",\"02\").str.replace(\"Mar\",\"03\").str.replace(\"Apr\",\"04\").str.replace(\"May\",\"05\").str.replace(\"Jun\",\"06\").str.replace(\"Jul\",\"07\").str.replace(\"Aug\",\"08\").str.replace(\"Sep\",\"09\").str.replace(\"Oct\",\"10\").str.replace(\"Nov\",\"11\").str.replace(\"Dec\",\"12\")\n",
    "\n",
    "df_sharks.loc[\n",
    "    df_sharks['Date_Comment'] ==\"MMM-yyyy\",\n",
    "    \"Date\"] = '01-' + df_sharks.loc[\n",
    "        df_sharks['Date_Comment'] == \"MMM-yyyy\",\n",
    "        \"Date\" ]\n",
    "\n",
    "df_sharks.loc[\n",
    "    df_sharks['Date_Comment'] ==\"Reported dd-MMM-yyyy\",\n",
    "    \"Date\"\n",
    "]=df_sharks.loc[\n",
    "    df_sharks['Date_Comment'] ==\"Reported dd-MMM-yyy\",\n",
    "    \"Date\"].str.replace(\"Jan\",\"01\").str.replace(\"Feb\",\"02\").str.replace(\"Mar\",\"03\").str.replace(\"Apr\",\"04\").str.replace(\"May\",\"05\").str.replace(\"Jun\",\"06\").str.replace(\"Jul\",\"07\").str.replace(\"Aug\",\"08\").str.replace(\"Sep\",\"09\").str.replace(\"Oct\",\"10\").str.replace(\"Nov\",\"11\").str.replace(\"Dec\",\"12\")\n",
    "\n",
    "df_sharks.loc[\n",
    "    df_sharks['Date_Comment'] ==\"Reported dd-MMM-yyyy\",\n",
    "    \"Date\"] = df_sharks.loc[\n",
    "    df_sharks['Date_Comment'] ==\"Reported dd-MMM-yyyy\",\n",
    "    \"Date\"].str.replace(\"Reported \",\"\")\n",
    "\n",
    "\n",
    "df_sharks['Date_Comment']= 'Check'\n",
    "\n",
    "dateregex1 = r'\\d{2}-[A-Za-z]{3}-\\d{4}'\n",
    "dateregex2 = r'^\\d{4}$'\n",
    "dateregex3 = r'^\\d{4}-\\d{4}$'\n",
    "dateregex4 = r'^Before \\d{4}$'\n",
    "dateregex5 = r'^Reported \\d{2}-[A-Za-z]{3}-\\d{4}$'\n",
    "dateregex6 = r'^[A-Za-z]{3}-\\d{4}$'\n",
    "dateregex7 = r'^(0[1-9]|[12][0-9]|3[01])-(0[1-9]|1[0-2])-\\d{4}$'\n",
    "\n",
    "\n",
    "df_sharks.loc[\n",
    "    df_sharks['Date'].str.match(dateregex1)==True,\n",
    "    'Date_Comment'\n",
    "    ]= \"Date, replace MMM, mm\"\n",
    "\n",
    "df_sharks.loc[\n",
    "    ((df_sharks[\"Date_Comment\"] == \"Check\")&\n",
    "    (df_sharks['Date'].str.match(dateregex2)==True)),\n",
    "    'Date_Comment'\n",
    "] = \"Only year, missing day and month\"\n",
    "\n",
    "df_sharks.loc[\n",
    "    ((df_sharks[\"Date_Comment\"] == \"Check\")&\n",
    "    (df_sharks['Date'].str.match(dateregex3)==True)),\n",
    "    'Date_Comment'\n",
    "] = \"YYYY-YYYY format-->Range of years\"\n",
    "\n",
    "df_sharks.loc[\n",
    "    ((df_sharks[\"Date_Comment\"] == \"Check\")&\n",
    "    (df_sharks['Date'].str.match(dateregex4)==True)),\n",
    "    'Date_Comment'\n",
    "] = \"Before YYYY format\"\n",
    "\n",
    "df_sharks.loc[\n",
    "    ((df_sharks[\"Date_Comment\"] == \"Check\")&\n",
    "    (df_sharks['Date'].str.match(dateregex5)==True)),\n",
    "    'Date_Comment'\n",
    "] = \"Reported dd-MMM-yyyy\"\n",
    "\n",
    "df_sharks.loc[\n",
    "    ((df_sharks[\"Date_Comment\"] == \"Check\")&\n",
    "    (df_sharks['Date'].str.match(dateregex6)==True)),\n",
    "    'Date_Comment'\n",
    "] = \"MMM-yyyy\"\n",
    "\n",
    "df_sharks.loc[\n",
    "    df_sharks['Date'].str.match(dateregex7)==True,\n",
    "    'Date_Comment'\n",
    "    ]= \"Date ok\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date_Comment</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Before YYYY format</th>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Check</th>\n",
       "      <td>688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date ok</th>\n",
       "      <td>5555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date, replace MMM, mm</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Only year, missing day and month</th>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YYYY-YYYY format--&gt;Range of years</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Date\n",
       "Date_Comment                           \n",
       "Before YYYY format                   57\n",
       "Check                               688\n",
       "Date ok                            5555\n",
       "Date, replace MMM, mm                 1\n",
       "Only year, missing day and month    138\n",
       "YYYY-YYYY format-->Range of years    16"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.pivot_table(df_sharks, index = \"Date_Comment\", values = \"Date\", aggfunc = \"count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 5555 entries, 30 to 6820\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype         \n",
      "---  ------        --------------  -----         \n",
      " 0   id            5555 non-null   int64         \n",
      " 1   Date          5554 non-null   datetime64[ns]\n",
      " 2   Year          5555 non-null   float64       \n",
      " 3   Date_Comment  5555 non-null   object        \n",
      " 4   Lenght        5555 non-null   int64         \n",
      "dtypes: datetime64[ns](1), float64(1), int64(2), object(1)\n",
      "memory usage: 260.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df_sharks = df_sharks.loc[df_sharks[\"Date_Comment\"] == \"Date ok\"]\n",
    "df_sharks[\"Lenght\"] = df_sharks[\"Date\"].astype(str).str.len()\n",
    "df_sharks['Date'] = pd.to_datetime(df_sharks['Date'], format='%d-%m-%Y', errors='coerce')\n",
    "\n",
    "df_sharks.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YEAR CLEAN UP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sharks[\"Year\"] = df_sharks[\"Date\"].dt.year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COUNTRY CLEAN UP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Country'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\xavie\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Country'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m df_sharks[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCountry_Comment\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCheck\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 2\u001b[0m df_sharks[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCountry\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39m df_sharks[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCountry\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[0;32m      3\u001b[0m countryregex \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m^[A-Z\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms]+$\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      4\u001b[0m countryregex2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m^(?:[A-Z][a-z]+(?:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms+[A-Z][a-z]+)*)?$|^(?:[A-Z][a-z]*\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms*)+$\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\xavie\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\xavie\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Country'"
     ]
    }
   ],
   "source": [
    "df_sharks['Country_Comment']= 'Check'\n",
    "df_sharks['Country']= df_sharks['Country'].str.strip()\n",
    "countryregex = r'^[A-Z\\s]+$'\n",
    "countryregex2 = r'^(?:[A-Z][a-z]+(?:\\s+[A-Z][a-z]+)*)?$|^(?:[A-Z][a-z]*\\s*)+$'\n",
    "countryregex3 = r'^[A-Z\\s]+ \\/ [A-Z\\s]+$'\n",
    "countryregex4 = r'^[A-Z]+(?:\\s[A-Z]+)*$'\n",
    "countryregex5 = r'^[A-Z\\s&]+$'\n",
    "\n",
    "df_sharks.loc[\n",
    "    df_sharks['Country'].str.match(countryregex)==True,\n",
    "    'Country_Comment'\n",
    "    ]= \"Country_ok\"\n",
    "\n",
    "pattern2 = r'^(?:[A-Z][a-z]+(?:\\s+[A-Z][a-z]+)*)?$|^(?:[A-Z][a-z]*\\s*)+$'\n",
    "\n",
    "df_sharks.loc[\n",
    "    (df_sharks['Country_Comment']=='Check') &\n",
    "    (df_sharks['Country'].str.match(countryregex2)==True),\n",
    "    'Country_Comment'\n",
    "    ] = 'Countries haveing First/Second word Capital Letter and rest smalls letters'\n",
    "\n",
    "\n",
    "df_sharks.loc[\n",
    "    (df_sharks['Country_Comment']=='Check') &\n",
    "    (df_sharks['Country'].str.match(countryregex3)==True),\n",
    "    'Country_Comment'\n",
    "    ] = 'Countries split by / but with capital letters'\n",
    "\n",
    "df_sharks.loc[\n",
    "    (df_sharks['Country_Comment']=='Check') &\n",
    "    (df_sharks['Country'].str.match(countryregex4)==True),\n",
    "    'Country_Comment'\n",
    "    ] = \"Country in capitals containing ?\"\n",
    "\n",
    "df_sharks.loc[\n",
    "    (df_sharks['Country_Comment']=='Check') &\n",
    "    (df_sharks['Country'].str.match(countryregex5)==True),\n",
    "    'Country_Comment'\n",
    "    ] = \"Country in capitals separated by &\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country_Comment</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Check</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Countries haveing First/Second word Capital Letter and rest smalls letters</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Countries split by / but with capital letters</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country in capitals separated by &amp;</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country_ok</th>\n",
       "      <td>5506</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Country\n",
       "Country_Comment                                            \n",
       "Check                                                     6\n",
       "Countries haveing First/Second word Capital Let...        8\n",
       "Countries split by / but with capital letters             6\n",
       "Country in capitals separated by &                        7\n",
       "Country_ok                                             5506"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.pivot_table(df_sharks, index = 'Country_Comment',values = 'Country',aggfunc='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sharks.loc[\n",
    "    ((df_sharks['Country_Comment']!='Country_ok') & \n",
    "    (df_sharks['Country_Comment']=='Country in capitals separated by &')),\n",
    "    [\"Country\"]\n",
    "              ] =  df_sharks.loc[\n",
    "                  ((df_sharks['Country_Comment'] != 'Country_ok') & \n",
    "                   (df_sharks['Country_Comment'] == 'Country in capitals separated by &')),\n",
    "                   ['Country']\n",
    "                   ].replace(\"&\", \"AND\", regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Location</th>\n",
       "      <th>State</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>ST KITTS / NEVIS</td>\n",
       "      <td>Booby Island</td>\n",
       "      <td>The Narrows</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2933</th>\n",
       "      <td>EGYPT / ISRAEL</td>\n",
       "      <td>1 km off the mouth of Marsa Bereika, north of ...</td>\n",
       "      <td>South Sinai, Gulf of Aqaba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4610</th>\n",
       "      <td>RED SEA / INDIAN OCEAN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Enroute from Suez to Aden (Yemen)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4793</th>\n",
       "      <td>ANDAMAN / NICOBAR ISLANDAS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5275</th>\n",
       "      <td>IRAN / IRAQ</td>\n",
       "      <td>Vicinity of Abadan</td>\n",
       "      <td>Shatt-al-Arab River</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5352</th>\n",
       "      <td>SOLOMON ISLANDS / VANUATU</td>\n",
       "      <td>North of Guadalcanal, Solomon Islands while en...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Country  \\\n",
       "346             ST KITTS / NEVIS   \n",
       "2933              EGYPT / ISRAEL   \n",
       "4610      RED SEA / INDIAN OCEAN   \n",
       "4793  ANDAMAN / NICOBAR ISLANDAS   \n",
       "5275                 IRAN / IRAQ   \n",
       "5352   SOLOMON ISLANDS / VANUATU   \n",
       "\n",
       "                                               Location  \\\n",
       "346                                        Booby Island   \n",
       "2933  1 km off the mouth of Marsa Bereika, north of ...   \n",
       "4610                                                NaN   \n",
       "4793                                                NaN   \n",
       "5275                                 Vicinity of Abadan   \n",
       "5352  North of Guadalcanal, Solomon Islands while en...   \n",
       "\n",
       "                                  State  \n",
       "346                         The Narrows  \n",
       "2933         South Sinai, Gulf of Aqaba  \n",
       "4610  Enroute from Suez to Aden (Yemen)  \n",
       "4793                                NaN  \n",
       "5275                Shatt-al-Arab River  \n",
       "5352                                NaN  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sharks.loc[\n",
    "    ((df_sharks['Country_Comment']!='Country_ok') & \n",
    "    (df_sharks['Country_Comment']=='Countries split by / but with capital letters')),\n",
    "    [\"Country\",\"Location\",\"State\"]\n",
    "             ]\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df_sharks.loc[\n",
    "    ((df_sharks['Country_Comment']!='Country_ok') & \n",
    "    (df_sharks['Country_Comment']=='Countries split by / but with capital letters') &\n",
    "    (df_sharks['State']==\"South Sinai, Gulf of Aqaba\")),\n",
    "    [\"Country\"]] = \"EGYPT\"\n",
    "df_sharks.loc[\n",
    "    ((df_sharks['Country_Comment']!='Country_ok') & \n",
    "    (df_sharks['Country_Comment']=='Countries split by / but with capital letters') &\n",
    "    (df_sharks['State']==\"Enroute from Suez to Aden (Yemen)\")),\n",
    "    [\"Country\"]] = \"RED SEA\"\n",
    "df_sharks.loc[\n",
    "    ((df_sharks['Country_Comment']!='Country_ok') & \n",
    "    (df_sharks['Country_Comment']=='Countries split by / but with capital letters') &\n",
    "    (df_sharks['State']== \"Shatt-al-Arab River\")),\n",
    "    [\"Country\"]] = \"IRAQ\"\n",
    "df_sharks.loc[\n",
    "    ((df_sharks['Country_Comment']!='Country_ok') & \n",
    "    (df_sharks['Country_Comment']=='Countries split by / but with capital letters') &\n",
    "    (df_sharks['Country']== \"SOLOMON ISLANDS / VANUATU\")),\n",
    "    [\"Country\"]] = \"SOLOMON ISLANDS\"\n",
    "\n",
    "df_sharks.loc[\n",
    "    ((df_sharks['Country_Comment']!='Country_ok') & \n",
    "    (df_sharks['Country_Comment']=='Countries split by / but with capital letters') &\n",
    "    (df_sharks['Location']== \"Kralievica\")),\n",
    "    [\"Country\"]] = \"CROATIA\"\n",
    "\n",
    "df_sharks.loc[\n",
    "    ((df_sharks['Country_Comment']!='Country_ok') & \n",
    "    (df_sharks['Country_Comment']=='Countries split by / but with capital letters') &\n",
    "    (df_sharks['State']==\"Fernando Po Island\")),\n",
    "    [\"Country\"]] = \"EQUATORIAL GUINEA\"\n",
    "\n",
    "#CLENAING SMALL LETTERS TO CAPITALS\n",
    "df_sharks.loc[\n",
    "    ((df_sharks['Country_Comment']!='Country_ok') & \n",
    "    (df_sharks['Country_Comment']=='Countries haveing First/Second word Capital Letter and rest smalls letters')),\n",
    "    \"Country\"\n",
    "    ] =  df_sharks.loc[\n",
    "        ((df_sharks['Country_Comment']!='Country_ok') & \n",
    "         (df_sharks['Country_Comment']=='Countries haveing First/Second word Capital Letter and rest smalls letters')),\n",
    "         \"Country\"\n",
    "         ].str.upper()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xavie\\AppData\\Local\\Temp\\ipykernel_17660\\2355470971.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_sharks['Country_Comment']= 'Check'\n",
      "C:\\Users\\xavie\\AppData\\Local\\Temp\\ipykernel_17660\\2355470971.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_sharks['Country']= df_sharks['Country'].str.strip()\n"
     ]
    }
   ],
   "source": [
    "df_sharks['Country_Comment']= 'Check'\n",
    "df_sharks['Country']= df_sharks['Country'].str.strip()\n",
    "countryregex = r'^[A-Z\\s]+$'\n",
    "countryregex2 = r'^(?:[A-Z][a-z]+(?:\\s+[A-Z][a-z]+)*)?$|^(?:[A-Z][a-z]*\\s*)+$'\n",
    "countryregex3 = r'^[A-Z\\s]+ \\/ [A-Z\\s]+$'\n",
    "countryregex4 = r'^[A-Z]+(?:\\s[A-Z]+)*$'\n",
    "countryregex5 = r'^[A-Z\\s&]+$'\n",
    "\n",
    "df_sharks.loc[\n",
    "    df_sharks['Country'].str.match(countryregex)==True,\n",
    "    'Country_Comment'\n",
    "    ]= \"Country_ok\"\n",
    "\n",
    "pattern2 = r'^(?:[A-Z][a-z]+(?:\\s+[A-Z][a-z]+)*)?$|^(?:[A-Z][a-z]*\\s*)+$'\n",
    "\n",
    "df_sharks.loc[\n",
    "    (df_sharks['Country_Comment']=='Check') &\n",
    "    (df_sharks['Country'].str.match(countryregex2)==True),\n",
    "    'Country_Comment'\n",
    "    ] = 'Countries haveing First/Second word Capital Letter and rest smalls letters'\n",
    "\n",
    "\n",
    "df_sharks.loc[\n",
    "    (df_sharks['Country_Comment']=='Check') &\n",
    "    (df_sharks['Country'].str.match(countryregex3)==True),\n",
    "    'Country_Comment'\n",
    "    ] = 'Countries split by / but with capital letters'\n",
    "\n",
    "df_sharks.loc[\n",
    "    (df_sharks['Country_Comment']=='Check') &\n",
    "    (df_sharks['Country'].str.match(countryregex4)==True),\n",
    "    'Country_Comment'\n",
    "    ] = \"Country in capitals containing ?\"\n",
    "\n",
    "df_sharks.loc[\n",
    "    (df_sharks['Country_Comment']=='Check') &\n",
    "    (df_sharks['Country'].str.match(countryregex5)==True),\n",
    "    'Country_Comment'\n",
    "    ] = \"Country in capitals separated by &\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sharks = df_sharks.loc[\n",
    "    df_sharks[\"Country_Comment\"]==\"Country_ok\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "countryregex6 = r'\\b\\w+\\s+SEA\\b'\n",
    "countryregex7 = r'\\b\\w+\\s+OCEAN\\b'\n",
    "countryregex8 = r'\\bBRITISH\\w*\\b'\n",
    "countryregex9 = r'\\b\\w*GULF\\w*\\b'\n",
    "\n",
    "\n",
    "\n",
    "df_sharks = df_sharks.loc[\n",
    "    (df_sharks['Country'].str.match(countryregex6)==False)|\n",
    "    (df_sharks['Country'].str.match(countryregex7)==False)|\n",
    "    (df_sharks['Country'].str.match(countryregex8)==False)|\n",
    "    (df_sharks['Country'].str.match(countryregex9)==False)\n",
    "    ]\n",
    "\n",
    "df_sharks.loc[\n",
    "    (df_sharks['Country'] == \"THE BALKANS\"),\n",
    "    \"Country\"\n",
    "] = \"SLOVENIA\"\n",
    "\n",
    "df_sharks.loc[\n",
    "    (df_sharks['Country'] == \"KOREA\"),\n",
    "    \"Country\"\n",
    "] = \"SOUTH KOREA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sharks.to_csv(r\"C:\\Users\\xavie\\OneDrive\\Documentos\\Ironhack\\Week 2\\Quest\\clean_date_year.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
